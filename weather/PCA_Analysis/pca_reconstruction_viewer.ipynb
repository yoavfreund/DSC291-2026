{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PCA Signal Reconstruction Viewer\n",
        "\n",
        "This notebook allows you to visualize the original weather signal and its reconstruction using PCA components and coefficients.\n",
        "\n",
        "**Features:**\n",
        "- Load PCA components and coefficients\n",
        "- Select a specific row/station to analyze\n",
        "- View progressive reconstruction: mean, mean+PC1, mean+PC1+PC2, etc.\n",
        "- Interactive visualization with matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA results directory: ../weather_info/pca_results/\n",
            "Coefficients file: ../../../weather_data/per_row_coefficients.parquet\n",
            "Files exist: PCA dir=True, Coefficients=True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up paths\n",
        "pca_results_dir = \"../weather_info/pca_results/\"\n",
        "coefficients_file = \"../../../weather_data/per_row_coefficients.parquet\"\n",
        "\n",
        "print(f\"PCA results directory: {pca_results_dir}\")\n",
        "print(f\"Coefficients file: {coefficients_file}\")\n",
        "print(f\"Files exist: PCA dir={os.path.exists(pca_results_dir)}, Coefficients={os.path.exists(coefficients_file)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded PCA results for SNWD: components (10, 365), mean (365,)\n",
            "Loaded PCA results for PRCP: components (10, 365), mean (365,)\n",
            "Loaded PCA results for TMIN: components (10, 365), mean (365,)\n",
            "Loaded PCA results for SNOW: components (10, 365), mean (365,)\n",
            "Loaded PCA results for TMAX: components (10, 365), mean (365,)\n",
            "Loaded PCA results for TOBS: components (10, 365), mean (365,)\n",
            "Loaded PCA results for TAVG: components (10, 365), mean (365,)\n",
            "\n",
            "Loaded PCA results for 7 measurement types: ['SNWD', 'PRCP', 'TMIN', 'SNOW', 'TMAX', 'TOBS', 'TAVG']\n"
          ]
        }
      ],
      "source": [
        "# Load PCA results for all measurement types\n",
        "def load_pca_results(pca_dir):\n",
        "    \"\"\"Load all PCA results from pickle files.\"\"\"\n",
        "    measurement_types = ['snwd', 'prcp', 'tmin', 'snow', 'tmax', 'tobs', 'tavg']\n",
        "    pca_results = {}\n",
        "    \n",
        "    for measurement in measurement_types:\n",
        "        pca_file = os.path.join(pca_dir, f\"{measurement}_pca_results.pkl\")\n",
        "        \n",
        "        if os.path.exists(pca_file):\n",
        "            try:\n",
        "                with open(pca_file, 'rb') as f:\n",
        "                    results = pickle.load(f)\n",
        "                    pca_results[measurement.upper()] = results\n",
        "                    print(f\"Loaded PCA results for {measurement.upper()}: \"\n",
        "                          f\"components {results['components'].shape}, \"\n",
        "                          f\"mean {results['mean'].shape}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {pca_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"PCA file not found: {pca_file}\")\n",
        "    \n",
        "    return pca_results\n",
        "\n",
        "# Load PCA results\n",
        "pca_results = load_pca_results(pca_results_dir)\n",
        "print(f\"\\nLoaded PCA results for {len(pca_results)} measurement types: {list(pca_results.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading coefficients data...\n",
            "Coefficients data shape: (7415065, 389)\n",
            "Columns: ['station_id_x', 'latitude', 'longitude', 'elevation', 'state', 'name', 'gsn_flag', 'hcn_crn_flag', 'wmo_id', 'ID', 'year', 'ELEMENT', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'day_8', 'day_9', 'day_10', 'day_11', 'day_12', 'day_13', 'day_14', 'day_15', 'day_16', 'day_17', 'day_18', 'day_19', 'day_20', 'day_21', 'day_22', 'day_23', 'day_24', 'day_25', 'day_26', 'day_27', 'day_28', 'day_29', 'day_30', 'day_31', 'day_32', 'day_33', 'day_34', 'day_35', 'day_36', 'day_37', 'day_38', 'day_39', 'day_40', 'day_41', 'day_42', 'day_43', 'day_44', 'day_45', 'day_46', 'day_47', 'day_48', 'day_49', 'day_50', 'day_51', 'day_52', 'day_53', 'day_54', 'day_55', 'day_56', 'day_57', 'day_58', 'day_59', 'day_60', 'day_61', 'day_62', 'day_63', 'day_64', 'day_65', 'day_66', 'day_67', 'day_68', 'day_69', 'day_70', 'day_71', 'day_72', 'day_73', 'day_74', 'day_75', 'day_76', 'day_77', 'day_78', 'day_79', 'day_80', 'day_81', 'day_82', 'day_83', 'day_84', 'day_85', 'day_86', 'day_87', 'day_88', 'day_89', 'day_90', 'day_91', 'day_92', 'day_93', 'day_94', 'day_95', 'day_96', 'day_97', 'day_98', 'day_99', 'day_100', 'day_101', 'day_102', 'day_103', 'day_104', 'day_105', 'day_106', 'day_107', 'day_108', 'day_109', 'day_110', 'day_111', 'day_112', 'day_113', 'day_114', 'day_115', 'day_116', 'day_117', 'day_118', 'day_119', 'day_120', 'day_121', 'day_122', 'day_123', 'day_124', 'day_125', 'day_126', 'day_127', 'day_128', 'day_129', 'day_130', 'day_131', 'day_132', 'day_133', 'day_134', 'day_135', 'day_136', 'day_137', 'day_138', 'day_139', 'day_140', 'day_141', 'day_142', 'day_143', 'day_144', 'day_145', 'day_146', 'day_147', 'day_148', 'day_149', 'day_150', 'day_151', 'day_152', 'day_153', 'day_154', 'day_155', 'day_156', 'day_157', 'day_158', 'day_159', 'day_160', 'day_161', 'day_162', 'day_163', 'day_164', 'day_165', 'day_166', 'day_167', 'day_168', 'day_169', 'day_170', 'day_171', 'day_172', 'day_173', 'day_174', 'day_175', 'day_176', 'day_177', 'day_178', 'day_179', 'day_180', 'day_181', 'day_182', 'day_183', 'day_184', 'day_185', 'day_186', 'day_187', 'day_188', 'day_189', 'day_190', 'day_191', 'day_192', 'day_193', 'day_194', 'day_195', 'day_196', 'day_197', 'day_198', 'day_199', 'day_200', 'day_201', 'day_202', 'day_203', 'day_204', 'day_205', 'day_206', 'day_207', 'day_208', 'day_209', 'day_210', 'day_211', 'day_212', 'day_213', 'day_214', 'day_215', 'day_216', 'day_217', 'day_218', 'day_219', 'day_220', 'day_221', 'day_222', 'day_223', 'day_224', 'day_225', 'day_226', 'day_227', 'day_228', 'day_229', 'day_230', 'day_231', 'day_232', 'day_233', 'day_234', 'day_235', 'day_236', 'day_237', 'day_238', 'day_239', 'day_240', 'day_241', 'day_242', 'day_243', 'day_244', 'day_245', 'day_246', 'day_247', 'day_248', 'day_249', 'day_250', 'day_251', 'day_252', 'day_253', 'day_254', 'day_255', 'day_256', 'day_257', 'day_258', 'day_259', 'day_260', 'day_261', 'day_262', 'day_263', 'day_264', 'day_265', 'day_266', 'day_267', 'day_268', 'day_269', 'day_270', 'day_271', 'day_272', 'day_273', 'day_274', 'day_275', 'day_276', 'day_277', 'day_278', 'day_279', 'day_280', 'day_281', 'day_282', 'day_283', 'day_284', 'day_285', 'day_286', 'day_287', 'day_288', 'day_289', 'day_290', 'day_291', 'day_292', 'day_293', 'day_294', 'day_295', 'day_296', 'day_297', 'day_298', 'day_299', 'day_300', 'day_301', 'day_302', 'day_303', 'day_304', 'day_305', 'day_306', 'day_307', 'day_308', 'day_309', 'day_310', 'day_311', 'day_312', 'day_313', 'day_314', 'day_315', 'day_316', 'day_317', 'day_318', 'day_319', 'day_320', 'day_321', 'day_322', 'day_323', 'day_324', 'day_325', 'day_326', 'day_327', 'day_328', 'day_329', 'day_330', 'day_331', 'day_332', 'day_333', 'day_334', 'day_335', 'day_336', 'day_337', 'day_338', 'day_339', 'day_340', 'day_341', 'day_342', 'day_343', 'day_344', 'day_345', 'day_346', 'day_347', 'day_348', 'day_349', 'day_350', 'day_351', 'day_352', 'day_353', 'day_354', 'day_355', 'day_356', 'day_357', 'day_358', 'day_359', 'day_360', 'day_361', 'day_362', 'day_363', 'day_364', 'day_365', 'station_id_y', 'dist_to_coast', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10']\n",
            "\n",
            "Sample data:\n",
            "  station_id_x  latitude  longitude  elevation state          name gsn_flag  \\\n",
            "0  AM000037618   41.1170    44.2830     1509.0  None        TASHIR     None   \n",
            "1  AM000037618   41.1170    44.2830     1509.0  None        TASHIR     None   \n",
            "2  AM000037618   41.1170    44.2830     1509.0  None        TASHIR     None   \n",
            "3  AM000037618   41.1170    44.2830     1509.0  None        TASHIR     None   \n",
            "4  AQC00914188  -14.2167  -168.5333        6.1    AS  FALEASAO TAU     None   \n",
            "\n",
            "  hcn_crn_flag   wmo_id           ID  ...          PC1         PC2  \\\n",
            "0         None  37618.0  AM000037618  ... -2594.343684  782.912038   \n",
            "1         None  37618.0  AM000037618  ... -2375.890014  634.796902   \n",
            "2         None  37618.0  AM000037618  ... -2582.462656  802.017290   \n",
            "3         None  37618.0  AM000037618  ... -2440.435998  638.402905   \n",
            "4         None      NaN  AQC00914188  ... -2607.424719  787.371707   \n",
            "\n",
            "          PC3         PC4         PC5         PC6        PC7         PC8  \\\n",
            "0  401.767151 -284.069092   35.530478  -24.344210 -15.008348   11.612688   \n",
            "1  445.077803 -276.304730 -118.498344  149.847955 -79.759613   60.861426   \n",
            "2  276.496484 -278.754658   36.242633  -12.078588 -15.748477   12.933766   \n",
            "3  418.280289 -165.922707  -45.912120  207.207464 -94.504445  112.815465   \n",
            "4  398.563002 -272.053129   43.123728  -11.205996 -18.555119   15.394226   \n",
            "\n",
            "         PC9        PC10  \n",
            "0 -24.687436   -2.114185  \n",
            "1  96.106899 -176.626259  \n",
            "2  -6.344720   -6.160414  \n",
            "3  30.549125 -162.363950  \n",
            "4 -14.026750    2.254954  \n",
            "\n",
            "[5 rows x 389 columns]\n",
            "\n",
            "Available measurement types: <StringArray>\n",
            "['SNWD', 'PRCP', 'TMIN', 'SNOW', 'TMAX', 'TOBS', 'TAVG']\n",
            "Length: 7, dtype: string\n"
          ]
        }
      ],
      "source": [
        "# Load coefficients data\n",
        "print(\"Loading coefficients data...\")\n",
        "coefficients_df = pd.read_parquet(coefficients_file)\n",
        "print(f\"Coefficients data shape: {coefficients_df.shape}\")\n",
        "print(f\"Columns: {coefficients_df.columns.tolist()}\")\n",
        "print(f\"\\nSample data:\")\n",
        "print(coefficients_df.head())\n",
        "\n",
        "# Check available measurement types in coefficients\n",
        "available_elements = coefficients_df['ELEMENT'].unique()\n",
        "print(f\"\\nAvailable measurement types: {available_elements}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstruction functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Function to reconstruct signal using PCA components and coefficients\n",
        "def reconstruct_signal(mean_values, components, coefficients, n_components=None):\n",
        "    \"\"\"\n",
        "    Reconstruct signal using PCA components and coefficients.\n",
        "    \n",
        "    Args:\n",
        "        mean_values: Mean values for centering (365,)\n",
        "        components: PCA components (n_components, 365)\n",
        "        coefficients: PCA coefficients for this row (n_components,)\n",
        "        n_components: Number of components to use (None = all)\n",
        "    \n",
        "    Returns:\n",
        "        Reconstructed signal (365,)\n",
        "    \"\"\"\n",
        "    if n_components is None:\n",
        "        n_components = len(coefficients)\n",
        "    \n",
        "    # Start with mean\n",
        "    reconstructed = mean_values.copy()\n",
        "    \n",
        "    # Add contributions from each component\n",
        "    for i in range(min(n_components, len(coefficients))):\n",
        "        reconstructed += coefficients[i] * components[i]\n",
        "    \n",
        "    return reconstructed\n",
        "\n",
        "# Function to get progressive reconstructions\n",
        "def get_progressive_reconstructions(mean_values, components, coefficients):\n",
        "    \"\"\"\n",
        "    Get reconstructions using 0, 1, 2, ..., n components.\n",
        "    \n",
        "    Returns:\n",
        "        List of reconstructed signals\n",
        "    \"\"\"\n",
        "    reconstructions = []\n",
        "    \n",
        "    # Start with just the mean\n",
        "    reconstructions.append(mean_values.copy())\n",
        "    \n",
        "    # Add components progressively\n",
        "    for i in range(len(coefficients)):\n",
        "        reconstructed = reconstruct_signal(mean_values, components, coefficients, i+1)\n",
        "        reconstructions.append(reconstructed)\n",
        "    \n",
        "    return reconstructions\n",
        "\n",
        "print(\"Reconstruction functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visualization function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Interactive function to visualize reconstruction for a specific row\n",
        "def visualize_reconstruction(row_idx, measurement_type, show_progressive=True, max_components=3, show_original=True):\n",
        "    \"\"\"\n",
        "    Visualize reconstruction for a specific row.\n",
        "    \n",
        "    Args:\n",
        "        row_idx: Index of the row to visualize\n",
        "        measurement_type: Type of measurement (e.g., 'TOBS')\n",
        "        show_progressive: Whether to show progressive reconstructions\n",
        "        max_components: Maximum number of components to show (default: 3)\n",
        "        show_original: Whether to show the original signal\n",
        "    \"\"\"\n",
        "    # Get the specific row\n",
        "    row_data = coefficients_df.iloc[row_idx]\n",
        "    \n",
        "    # Verify measurement type matches\n",
        "    if row_data['ELEMENT'] != measurement_type:\n",
        "        print(f\"Warning: Row {row_idx} has element {row_data['ELEMENT']}, not {measurement_type}\")\n",
        "        return\n",
        "    \n",
        "    # Get PCA results for this measurement type\n",
        "    if measurement_type not in pca_results:\n",
        "        print(f\"No PCA results found for {measurement_type}\")\n",
        "        return\n",
        "    \n",
        "    pca_data = pca_results[measurement_type]\n",
        "    mean_values = pca_data['mean']\n",
        "    components = pca_data['components']\n",
        "    \n",
        "    # Get coefficients for this row\n",
        "    coefficients = [row_data[f'PC{i+1}'] for i in range(10)]\n",
        "    \n",
        "    # Get original signal (reconstructed with all components)\n",
        "    original_signal = reconstruct_signal(mean_values, components, coefficients)\n",
        "    \n",
        "    # Get reconstruction with only top 3 components\n",
        "    reconstruction_3pc = reconstruct_signal(mean_values, components, coefficients, n_components=3)\n",
        "    \n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(15, 8))\n",
        "    \n",
        "    # Days of year for x-axis\n",
        "    days = np.arange(1, 366)\n",
        "    \n",
        "    if show_progressive:\n",
        "        # Show progressive reconstructions\n",
        "        reconstructions = get_progressive_reconstructions(mean_values, components, coefficients)\n",
        "        \n",
        "        # Plot mean only\n",
        "        ax.plot(days, reconstructions[0], 'k--', alpha=0.7, linewidth=2, label='Mean only')\n",
        "        \n",
        "        # Plot progressive reconstructions (up to max_components)\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, min(max_components, len(reconstructions)-1)))\n",
        "        for i in range(1, min(max_components+1, len(reconstructions))):\n",
        "            ax.plot(days, reconstructions[i], color=colors[i-1], alpha=0.8, \n",
        "                   label=f'Mean + PC1-{i}')\n",
        "        \n",
        "        # Plot reconstruction with top 3 components\n",
        "        ax.plot(days, reconstruction_3pc, 'b-', linewidth=3, label=f'Reconstruction (Top {max_components} PCs)')\n",
        "        \n",
        "        # Always plot original signal\n",
        "        ax.plot(days, original_signal, 'r-', linewidth=2, alpha=0.8, label='Original Signal (All PCs)')\n",
        "        \n",
        "    else:\n",
        "        # Just show mean, reconstruction with top 3, and original\n",
        "        ax.plot(days, mean_values, 'k--', alpha=0.7, linewidth=2, label='Mean')\n",
        "        ax.plot(days, reconstruction_3pc, 'b-', linewidth=3, label=f'Reconstruction (Top {max_components} PCs)')\n",
        "        # Always plot original signal\n",
        "        ax.plot(days, original_signal, 'r-', linewidth=2, alpha=0.8, label='Original Signal (All PCs)')\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_xlabel('Day of Year')\n",
        "    ax.set_ylabel(f'{measurement_type} Value')\n",
        "    ax.set_title(f'{measurement_type} Signal Reconstruction\\n'\n",
        "                f'Row {row_idx} (Station: {row_data.get(\"ID\", \"Unknown\")}, '\n",
        "                f'Year: {row_data.get(\"year\", \"Unknown\")})')\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add month labels\n",
        "    month_boundaries = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366]\n",
        "    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '']\n",
        "    ax.set_xticks(month_boundaries)\n",
        "    ax.set_xticklabels(month_labels)\n",
        "    ax.set_xlim(1, 365)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print coefficient information\n",
        "    print(f\"\\nPCA Coefficients for Row {row_idx}:\")\n",
        "    for i, coeff in enumerate(coefficients):\n",
        "        print(f\"  PC{i+1}: {coeff:.4f}\")\n",
        "    \n",
        "    # Print explained variance information\n",
        "    explained_variances = pca_data['explained_variances']\n",
        "    explained_variance_ratios = pca_data['explained_variance_ratios']\n",
        "    print(f\"\\nExplained Variance Ratios:\")\n",
        "    for i in range(min(10, len(explained_variance_ratios))):\n",
        "        print(f\"  PC{i+1}: {explained_variance_ratios[i]:.4f} ({explained_variance_ratios[i]*100:.2f}%)\")\n",
        "    \n",
        "    # Calculate reconstruction error with top 3 components\n",
        "    reconstruction_error = np.mean((original_signal - reconstruction_3pc) ** 2)\n",
        "    print(f\"\\nReconstruction Error (Top 3 PCs): {reconstruction_error:.6f}\")\n",
        "    print(f\"Explained Variance (Top 3 PCs): {explained_variance_ratios[:3].sum():.4f} ({explained_variance_ratios[:3].sum()*100:.2f}%)\")\n",
        "    \n",
        "    # Calculate how close the original signal is to the mean\n",
        "    mean_distance = np.mean((original_signal - mean_values) ** 2)\n",
        "    print(f\"Distance from Mean: {mean_distance:.6f}\")\n",
        "\n",
        "print(\"Visualization function defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal finding function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Function to find signals close to the mean\n",
        "def find_signals_close_to_mean(measurement_type, n_samples=5, years_range=(2000, 2025)):\n",
        "    \"\"\"\n",
        "    Find signals that are close to the mean signal.\n",
        "    \n",
        "    Args:\n",
        "        measurement_type: Type of measurement (e.g., 'TOBS')\n",
        "        n_samples: Number of signals to return\n",
        "        years_range: Tuple of (start_year, end_year) to filter by\n",
        "        \n",
        "    Returns:\n",
        "        List of row indices sorted by distance from mean (closest first)\n",
        "    \"\"\"\n",
        "    if measurement_type not in pca_results:\n",
        "        print(f\"No PCA results found for {measurement_type}\")\n",
        "        return []\n",
        "    \n",
        "    # Filter data for the measurement type and years\n",
        "    filtered_df = coefficients_df[coefficients_df['ELEMENT'] == measurement_type]\n",
        "    filtered_df = filtered_df[(filtered_df['year'] >= years_range[0]) & \n",
        "                              (filtered_df['year'] <= years_range[1])]\n",
        "    \n",
        "    if len(filtered_df) == 0:\n",
        "        print(f\"No data found for {measurement_type} in years {years_range[0]}-{years_range[1]}\")\n",
        "        return []\n",
        "    \n",
        "    # Get PCA data\n",
        "    pca_data = pca_results[measurement_type]\n",
        "    mean_values = pca_data['mean']\n",
        "    components = pca_data['components']\n",
        "    \n",
        "    # Calculate distance from mean for each row\n",
        "    distances = []\n",
        "    for idx in filtered_df.index:\n",
        "        row_data = filtered_df.loc[idx]\n",
        "        coefficients = [row_data[f'PC{i+1}'] for i in range(10)]\n",
        "        original_signal = reconstruct_signal(mean_values, components, coefficients)\n",
        "        distance = np.mean((original_signal - mean_values) ** 2)\n",
        "        distances.append((idx, distance))\n",
        "    \n",
        "    # Sort by distance (closest first)\n",
        "    distances.sort(key=lambda x: x[1])\n",
        "    \n",
        "    # Return the closest n_samples\n",
        "    closest_indices = [idx for idx, _ in distances[:n_samples]]\n",
        "    \n",
        "    print(f\"Found {len(closest_indices)} signals close to mean for {measurement_type}:\")\n",
        "    for i, (idx, distance) in enumerate(distances[:n_samples]):\n",
        "        row_data = filtered_df.loc[idx]\n",
        "        print(f\"  {i+1}. Row {idx}: Station {row_data.get('ID', 'Unknown')}, \"\n",
        "              f\"Year {row_data.get('year', 'Unknown')}, Distance: {distance:.6f}\")\n",
        "    \n",
        "    return closest_indices\n",
        "\n",
        "print(\"Signal finding function defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Visualization\n",
        "\n",
        "Now you can visualize signal reconstructions! Here are some examples:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Finding TOBS Signals Close to Mean ===\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'YEAR'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/.conda/envs/dask-tutorial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/.conda/envs/dask-tutorial/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/.conda/envs/dask-tutorial/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'YEAR'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Finding TOBS Signals Close to Mean ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Find signals close to the mean\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m closest_indices \u001b[38;5;241m=\u001b[39m \u001b[43mfind_signals_close_to_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTOBS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2025\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(closest_indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Visualize the closest signal to the mean\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     closest_idx \u001b[38;5;241m=\u001b[39m closest_indices[\u001b[38;5;241m0\u001b[39m]\n",
            "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mfind_signals_close_to_mean\u001b[0;34m(measurement_type, n_samples, years_range)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Filter data for the measurement type and years\u001b[39;00m\n\u001b[1;32m     19\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m coefficients_df[coefficients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mELEMENT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m measurement_type]\n\u001b[0;32m---> 20\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m filtered_df[(\u001b[43mfiltered_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYEAR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m years_range[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     21\u001b[0m                           (filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m years_range[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filtered_df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeasurement_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in years \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myears_range[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myears_range[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/dask-tutorial/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/.conda/envs/dask-tutorial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'YEAR'"
          ]
        }
      ],
      "source": [
        "# Example: Find signals close to the mean and visualize the closest one\n",
        "if 'TOBS' in pca_results:\n",
        "    print(\"=== Finding TOBS Signals Close to Mean ===\")\n",
        "    \n",
        "    # Find signals close to the mean\n",
        "    closest_indices = find_signals_close_to_mean('TOBS', n_samples=3, years_range=(2000, 2025))\n",
        "    \n",
        "    if len(closest_indices) > 0:\n",
        "        # Visualize the closest signal to the mean\n",
        "        closest_idx = closest_indices[0]\n",
        "        print(f\"\\nVisualizing the signal closest to mean:\")\n",
        "        visualize_reconstruction(closest_idx, 'TOBS', show_progressive=True, max_components=3)\n",
        "        \n",
        "        # Also visualize the second closest\n",
        "        if len(closest_indices) > 1:\n",
        "            print(f\"\\nVisualizing the second closest signal to mean:\")\n",
        "            visualize_reconstruction(closest_indices[1], 'TOBS', show_progressive=True, max_components=3)\n",
        "    else:\n",
        "        print(\"No TOBS signals found close to mean\")\n",
        "else:\n",
        "    print(\"TOBS PCA results not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Compare signals close to mean vs far from mean\n",
        "if 'TOBS' in pca_results:\n",
        "    print(\"=== Comparing Signals Close to Mean vs Far from Mean ===\")\n",
        "    \n",
        "    # Find signals close to the mean\n",
        "    closest_indices = find_signals_close_to_mean('TOBS', n_samples=2, years_range=(2000, 2025))\n",
        "    \n",
        "    # Find signals far from the mean (highest coefficient magnitudes)\n",
        "    filtered_df = coefficients_df[coefficients_df['ELEMENT'] == 'TOBS']\n",
        "    filtered_df = filtered_df[(filtered_df['year'] >= 2000) & (filtered_df['year'] <= 2025)]\n",
        "    \n",
        "    if len(filtered_df) > 0:\n",
        "        # Calculate coefficient magnitudes\n",
        "        pc_cols = [f'PC{i+1}' for i in range(10)]\n",
        "        coefficient_magnitudes = filtered_df[pc_cols].abs().sum(axis=1)\n",
        "        farthest_indices = coefficient_magnitudes.nlargest(2).index.tolist()\n",
        "        \n",
        "        print(f\"\\nSignals far from mean (highest coefficient magnitudes):\")\n",
        "        for i, idx in enumerate(farthest_indices):\n",
        "            row_data = filtered_df.loc[idx]\n",
        "            magnitude = coefficient_magnitudes[idx]\n",
        "            print(f\"  {i+1}. Row {idx}: Station {row_data.get('ID', 'Unknown')}, \"\n",
        "                  f\"Year {row_data.get('year', 'Unknown')}, Magnitude: {magnitude:.4f}\")\n",
        "        \n",
        "        # Visualize comparison\n",
        "        if len(closest_indices) > 0 and len(farthest_indices) > 0:\n",
        "            print(f\"\\n=== Signal Close to Mean ===\")\n",
        "            visualize_reconstruction(closest_indices[0], 'TOBS', show_progressive=True, max_components=3)\n",
        "            \n",
        "            print(f\"\\n=== Signal Far from Mean ===\")\n",
        "            visualize_reconstruction(farthest_indices[0], 'TOBS', show_progressive=True, max_components=3)\n",
        "    else:\n",
        "        print(\"No TOBS data found for comparison\")\n",
        "else:\n",
        "    print(\"TOBS PCA results not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Find signals close to the mean and visualize the closest one\n",
        "if 'TOBS' in pca_results:\n",
        "    print(\"=== Finding TOBS Signals Close to Mean ===\")\n",
        "    \n",
        "    # Find signals close to the mean\n",
        "    closest_indices = find_signals_close_to_mean('TOBS', n_samples=3, years_range=(2000, 2025))\n",
        "    \n",
        "    if len(closest_indices) > 0:\n",
        "        # Visualize the closest signal to the mean\n",
        "        closest_idx = closest_indices[0]\n",
        "        print(f\"\\nVisualizing the signal closest to mean:\")\n",
        "        visualize_reconstruction(closest_idx, 'TOBS', show_progressive=True, max_components=3)\n",
        "        \n",
        "        # Also visualize the second closest\n",
        "        if len(closest_indices) > 1:\n",
        "            print(f\"\\nVisualizing the second closest signal to mean:\")\n",
        "            visualize_reconstruction(closest_indices[1], 'TOBS', show_progressive=True, max_components=3)\n",
        "    else:\n",
        "        print(\"No TOBS signals found close to mean\")\n",
        "else:\n",
        "    print(\"TOBS PCA results not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Visualize a specific row (you can change the row index)\n",
        "measurement_type = 'TOBS'  # Change this to any available measurement type\n",
        "row_index = 2000  # Change this to any valid row index\n",
        "\n",
        "print(f\"=== Visualizing Row {row_index} for {measurement_type} ===\")\n",
        "visualize_reconstruction(row_index, measurement_type, show_progressive=True, max_components=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Compare different measurement types\n",
        "def compare_measurements(row_index, measurement_types):\n",
        "    \"\"\"Compare reconstructions for different measurement types.\"\"\"\n",
        "    fig, axes = plt.subplots(len(measurement_types), 1, figsize=(15, 4*len(measurement_types)))\n",
        "    \n",
        "    if len(measurement_types) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, measurement_type in enumerate(measurement_types):\n",
        "        if measurement_type not in pca_results:\n",
        "            continue\n",
        "            \n",
        "        # Get row data\n",
        "        row_data = coefficients_df.iloc[row_index]\n",
        "        \n",
        "        # Get PCA data\n",
        "        pca_data = pca_results[measurement_type]\n",
        "        mean_values = pca_data['mean']\n",
        "        components = pca_data['components']\n",
        "        \n",
        "        # Get coefficients\n",
        "        coefficients = [row_data[f'PC{i+1}'] for i in range(10)]\n",
        "        \n",
        "        # Reconstruct signal\n",
        "        reconstructed = reconstruct_signal(mean_values, components, coefficients)\n",
        "        \n",
        "        # Plot\n",
        "        days = np.arange(1, 366)\n",
        "        axes[i].plot(days, mean_values, 'k--', alpha=0.7, label='Mean')\n",
        "        axes[i].plot(days, reconstructed, 'b-', linewidth=2, label='Reconstruction')\n",
        "        axes[i].set_title(f'{measurement_type} - Row {row_index}')\n",
        "        axes[i].set_ylabel(f'{measurement_type} Value')\n",
        "        axes[i].legend()\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add month labels\n",
        "        month_boundaries = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366]\n",
        "        month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "                       'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '']\n",
        "        axes[i].set_xticks(month_boundaries)\n",
        "        axes[i].set_xticklabels(month_labels)\n",
        "        axes[i].set_xlim(1, 365)\n",
        "    \n",
        "    axes[-1].set_xlabel('Day of Year')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Compare TOBS, TMAX, TMIN for the same row\n",
        "compare_measurements(1000, ['TOBS', 'TMAX', 'TMIN'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Analysis\n",
        "\n",
        "You can now:\n",
        "1. **Change the row index** in the examples above to analyze different stations/years\n",
        "2. **Change the measurement type** to analyze different weather variables\n",
        "3. **Adjust max_components** to see how many PCA components are needed for good reconstruction\n",
        "4. **Use the functions** to create your own custom visualizations\n",
        "\n",
        "### Available Functions:\n",
        "- `visualize_reconstruction(row_idx, measurement_type, show_progressive=True, max_components=3)`\n",
        "- `find_signals_close_to_mean(measurement_type, n_samples=5, years_range=(2000, 2025))`\n",
        "- `compare_measurements(row_index, measurement_types)`\n",
        "- `reconstruct_signal(mean_values, components, coefficients, n_components=None)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick summary of available data\n",
        "print(\"=== Data Summary ===\")\n",
        "print(f\"Total rows in coefficients: {len(coefficients_df)}\")\n",
        "print(f\"Available measurement types: {list(coefficients_df['ELEMENT'].unique())}\")\n",
        "print(f\"Available PCA results: {list(pca_results.keys())}\")\n",
        "\n",
        "print(\"\\nRows per measurement type:\")\n",
        "for element in coefficients_df['ELEMENT'].unique():\n",
        "    count = len(coefficients_df[coefficients_df['ELEMENT'] == element])\n",
        "    print(f\"  {element}: {count:,} rows\")\n",
        "\n",
        "print(\"\\nPCA Components per measurement type:\")\n",
        "for measurement, data in pca_results.items():\n",
        "    print(f\"  {measurement}: {data['components'].shape[0]} components, \"\n",
        "          f\"explained variance: {data['explained_variance_ratios'][:3].sum():.3f} (top 3)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dask-tutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
