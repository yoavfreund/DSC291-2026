{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAM (Generalized Additive Models) Exploration\n",
    "\n",
    "This notebook explores algorithms for fitting Generalized Additive Models (GAMs) to data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "GAMs are a flexible class of models that extend linear models by allowing non-linear relationships between predictors and the response variable. They use smooth functions to model the relationship between each predictor and the response.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Additive Structure**: GAMs assume that the response is the sum of smooth functions of individual predictors\n",
    "2. **Smooth Functions**: Use splines or other smooth functions to capture non-linear relationships\n",
    "3. **Penalized Estimation**: Use penalties to control the smoothness of the fitted functions\n",
    "4. **Model Selection**: Choose appropriate smoothness parameters and model complexity\n",
    "\n",
    "## Libraries for GAMs\n",
    "\n",
    "- **pygam**: Python implementation of GAMs\n",
    "- **scikit-learn**: Limited GAM support\n",
    "- **statsmodels**: GAM implementation\n",
    "- **mgcv**: R package (via rpy2)\n",
    "\n",
    "## Analysis Plan\n",
    "\n",
    "1. **Data Preparation**: Load and prepare weather data for GAM analysis\n",
    "2. **Basic GAM Fitting**: Fit simple GAMs to temperature data\n",
    "3. **Algorithm Comparison**: Compare different GAM fitting algorithms\n",
    "4. **Model Selection**: Explore methods for choosing optimal smoothness parameters\n",
    "5. **Visualization**: Create plots to visualize fitted smooth functions\n",
    "6. **Performance Evaluation**: Assess model performance and interpretability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Loading\n",
    "\n",
    "First, we'll set up the environment and load the necessary libraries for GAM analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install and Import GAM Libraries\n",
    "\n",
    "We'll install and import the necessary GAM libraries. We'll start with pygam as it's a popular Python GAM implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygam already installed\n",
      "statsmodels GAM not available\n",
      "GAM libraries ready!\n"
     ]
    }
   ],
   "source": [
    "# Install pygam if not already installed\n",
    "try:\n",
    "    from pygam import LinearGAM, s, f\n",
    "    print(\"pygam already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing pygam...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"pygam\"])\n",
    "    from pygam import LinearGAM, s, f\n",
    "    print(\"pygam installed successfully\")\n",
    "\n",
    "# Also try to import statsmodels GAM\n",
    "try:\n",
    "    from statsmodels.gam.api import GLMGam, BSplines\n",
    "    print(\"statsmodels GAM available\")\n",
    "except ImportError:\n",
    "    print(\"statsmodels GAM not available\")\n",
    "\n",
    "print(\"GAM libraries ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Weather Data\n",
    "\n",
    "Load temperature data that we can use for GAM analysis. We'll use the TAVG data from our previous analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32639 TAVG records\n",
      "Years: [2020, 2022, 2023, 2024, 2025]\n",
      "Stations: 7017\n"
     ]
    }
   ],
   "source": [
    "# Load weather data\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load TAVG data from the combined weather dataset\n",
    "try:\n",
    "    tavg_data = dd.read_parquet('../../../weather_data/weather_1950_2025_combined.parquet').query(\n",
    "        \"ELEMENT == 'TAVG' and year >= 2020 and year <= 2025\"\n",
    "    ).compute()\n",
    "    \n",
    "    print(f\"Loaded {len(tavg_data)} TAVG records\")\n",
    "    print(f\"Years: {sorted(tavg_data['year'].unique())}\")\n",
    "    print(f\"Stations: {tavg_data['ID'].nunique()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Weather data file not found. Creating synthetic data for demonstration.\")\n",
    "    \n",
    "    # Create synthetic temperature data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_stations = 100\n",
    "    n_days = 365\n",
    "    \n",
    "    # Create synthetic temperature data with seasonal patterns\n",
    "    days = np.arange(1, n_days + 1)\n",
    "    \n",
    "    # Base temperature with seasonal variation\n",
    "    base_temp = 15 + 10 * np.sin(2 * np.pi * days / 365)\n",
    "    \n",
    "    # Add station-specific variations\n",
    "    station_effects = np.random.normal(0, 5, n_stations)\n",
    "    \n",
    "    # Create temperature matrix\n",
    "    temp_data = []\n",
    "    for i in range(n_stations):\n",
    "        station_temp = base_temp + station_effects[i] + np.random.normal(0, 2, n_days)\n",
    "        temp_data.append({\n",
    "            'station_id': f'STATION_{i:03d}',\n",
    "            'latitude': np.random.uniform(20, 60),\n",
    "            'longitude': np.random.uniform(-120, -70),\n",
    "            'temperature': station_temp\n",
    "        })\n",
    "    \n",
    "    tavg_data = pd.DataFrame(temp_data)\n",
    "    print(f\"Created synthetic data with {len(tavg_data)} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Basic GAM Fitting\n",
    "\n",
    "Now let's fit our first GAM using pygam. We'll start with a simple model that uses smooth functions of day of year to predict temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
